keep the naive reward for all these plots, and maybe try out different rewards and replicate the plots and see what changed

1. plot the certainty equivavelnt on the mean reward plot and see it coming up
2. plot the certainty equivavelt on another plot like mean reward
3. plot the T horizont changing do it for different trained models (mean reward, certainty equivavelnt)
	one training cycle for each T
	(could even do one training cycle and do a snapshot at each target T)
	(the time horizon could even be a training variable)
4. plot the reward of the optimal strategy on the above three plots (red dots parallel with x axis)


